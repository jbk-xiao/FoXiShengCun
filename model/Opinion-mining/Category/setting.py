# 最大句子长度
maxlen = 100

# 最大的tokenizer字典长度
max_words = 1000

# 设置embedding大小
embedding_dim = 300

# train_method : 模型训练方式textcnn
train_method = 'bilstm'

# 模型的保存位置，后续用于推理
ca_model_path_m = 'model_saved/model4.h5'

# 离线保存tokenizer
tokenize_path = 'model_saved/tokenizer4.pickle'